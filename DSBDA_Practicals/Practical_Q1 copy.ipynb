{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f1c0b9",
   "metadata": {},
   "source": [
    "## **Data Wrangling**\n",
    "\n",
    "Perform the following operations using Python on any open source dataset (e.g., data.csv)\n",
    "1. Import all the required Python Libraries.\n",
    "2. Locate an open source data from the web (e.g., https://www.kaggle.com). Provide a clear\n",
    " description of the data and its source (i.e., URL of the web site).\n",
    "3. Load the Dataset into pandas dataframe.\n",
    "4. Data Preprocessing: check for missing values in the data using pandas isnull(), describe()\n",
    "function to get some initial statistics. Provide variable descriptions. Types of variables etc.\n",
    "Check the dimensions of the data frame.\n",
    "5. Data Formatting and Data Normalization: Summarize the types of variables by checking\n",
    "the data types (i.e., character, numeric, integer, factor, and logical) of the variables in the\n",
    "data set. If variables are not in the correct data type, apply proper type conversions.\n",
    "6. Turn categorical variables into quantitative variables in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "730cde35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index          Job Title               Salary Estimate  \\\n",
      "0      0  Sr Data Scientist  $137K-$171K (Glassdoor est.)   \n",
      "1      1     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
      "2      2     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
      "3      3     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
      "4      4     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
      "\n",
      "                                     Job Description  Rating  \\\n",
      "0  Description\\n\\nThe Senior Data Scientist is re...     3.1   \n",
      "1  Secure our Nation, Ignite your Future\\n\\nJoin ...     4.2   \n",
      "2  Overview\\n\\n\\nAnalysis Group is one of the lar...     3.8   \n",
      "3  JOB DESCRIPTION:\\n\\nDo you have a passion for ...     3.5   \n",
      "4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n",
      "\n",
      "              Company Name       Location            Headquarters  \\\n",
      "0         Healthfirst\\n3.1   New York, NY            New York, NY   \n",
      "1             ManTech\\n4.2  Chantilly, VA             Herndon, VA   \n",
      "2      Analysis Group\\n3.8     Boston, MA              Boston, MA   \n",
      "3             INFICON\\n3.5     Newton, MA  Bad Ragaz, Switzerland   \n",
      "4  Affinity Solutions\\n2.9   New York, NY            New York, NY   \n",
      "\n",
      "                      Size  Founded        Type of ownership  \\\n",
      "0   1001 to 5000 employees     1993   Nonprofit Organization   \n",
      "1  5001 to 10000 employees     1968         Company - Public   \n",
      "2   1001 to 5000 employees     1981  Private Practice / Firm   \n",
      "3    501 to 1000 employees     2000         Company - Public   \n",
      "4      51 to 200 employees     1998        Company - Private   \n",
      "\n",
      "                                Industry             Sector  \\\n",
      "0                     Insurance Carriers          Insurance   \n",
      "1                 Research & Development  Business Services   \n",
      "2                             Consulting  Business Services   \n",
      "3  Electrical & Electronic Manufacturing      Manufacturing   \n",
      "4                Advertising & Marketing  Business Services   \n",
      "\n",
      "                      Revenue  \\\n",
      "0    Unknown / Non-Applicable   \n",
      "1      $1 to $2 billion (USD)   \n",
      "2  $100 to $500 million (USD)   \n",
      "3  $100 to $500 million (USD)   \n",
      "4    Unknown / Non-Applicable   \n",
      "\n",
      "                                         Competitors  \n",
      "0            EmblemHealth, UnitedHealth Group, Aetna  \n",
      "1                                                 -1  \n",
      "2                                                 -1  \n",
      "3  MKS Instruments, Pfeiffer Vacuum, Agilent Tech...  \n",
      "4               Commerce Signals, Cardlytics, Yodlee  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "job_data = pd.read_csv(\"./datasets/DS_jobs.csv\")\n",
    "print(job_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec0ffb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            index      Rating      Founded\n",
      "count  672.000000  672.000000   672.000000\n",
      "mean   335.500000    3.518601  1635.529762\n",
      "std    194.133974    1.410329   756.746640\n",
      "min      0.000000   -1.000000    -1.000000\n",
      "25%    167.750000    3.300000  1917.750000\n",
      "50%    335.500000    3.800000  1995.000000\n",
      "75%    503.250000    4.300000  2009.000000\n",
      "max    671.000000    5.000000  2019.000000\n"
     ]
    }
   ],
   "source": [
    "print(job_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161484d",
   "metadata": {},
   "source": [
    "## 2. Check for missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e21c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n",
      "\n",
      "Columns            Datatypes\n",
      "****************************\n",
      "index                  int64\n",
      "Job Title                str\n",
      "Salary Estimate          str\n",
      "Job Description          str\n",
      "Rating               float64\n",
      "Company Name             str\n",
      "Location                 str\n",
      "Headquarters             str\n",
      "Size                     str\n",
      "Founded                int64\n",
      "Type of ownership        str\n",
      "Industry                 str\n",
      "Sector                   str\n",
      "Revenue                  str\n",
      "Competitors              str\n",
      "dtype: object\n",
      "****************************\n",
      "\n",
      "Dimension of Job dataset is:- (672, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols_with_nan = job_data.columns[job_data.isnull().any()].tolist()\n",
    "\n",
    "\n",
    "print(f\"No of columns with Nan: {len(cols_with_nan)}\" if cols_with_nan else \"No missing values\")\n",
    "print(f\"\\nColumns{\" \":<12}Datatypes\\n\"+'*'*28)\n",
    "print(job_data.dtypes)\n",
    "print('*'*28+'\\n')\n",
    "print(f\"Dimension of Job dataset is:- {job_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142caded",
   "metadata": {},
   "source": [
    "## 2. Salary and Location Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c506198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Cities: 23\n",
      "Missing States: 23\n"
     ]
    }
   ],
   "source": [
    "# Extracting min-max Salary Estimate and converting them to numeric\n",
    "salary_text = job_data['Salary Estimate'].str.replace('K', '').str.replace('$', '')\n",
    "job_data[['min_salary', 'max_salary']] = salary_text.str.extract(r'(\\d+)-(\\d+)')\n",
    "job_data['min_salary'] = pd.to_numeric(job_data['min_salary'])\n",
    "job_data['max_salary'] = pd.to_numeric(job_data['max_salary'])\n",
    "\n",
    "#\n",
    "# job_data[['city', 'state']] = job_data['Location'].str.extract(r'^(.*),\\s(\\w{2})$')\n",
    "job_data[['city', 'state']] = job_data['Location'].str.extract(r'^(.*?),\\s*([A-Z]{2})$')\n",
    "\n",
    "print(f\"Missing Cities: {job_data['city'].isnull().sum()}\")\n",
    "print(f\"Missing States: {job_data['state'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305d9412",
   "metadata": {},
   "source": [
    "## 2.2 Clean Geographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91872b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows after cleaning: 649\n"
     ]
    }
   ],
   "source": [
    "job_data.dropna(subset=['city', 'state'], inplace=True)\n",
    "\n",
    "# Reset index after dropping rows\n",
    "job_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Remaining rows after cleaning: {job_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed890f",
   "metadata": {},
   "source": [
    "## 3. Revenue Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "838bf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_revenue(rev_str):\n",
    "    rev_str = str(rev_str).lower()\n",
    "    if 'billion' in rev_str:\n",
    "        if '1 to 2' in rev_str: return '1B'\n",
    "        if '2 to 5' in rev_str: return '5B'\n",
    "        if '5 to 10' in rev_str: return '10B'\n",
    "        return '50B'\n",
    "    elif 'million' in rev_str:\n",
    "        if '100 to 500' in rev_str: return '500M'\n",
    "        if '50 to 100' in rev_str: return '100M'\n",
    "        if '25 to 50' in rev_str: return '50M'\n",
    "        if '10 to 25' in rev_str: return '25M'\n",
    "        return '10M'\n",
    "    return 'Unknown'\n",
    "\n",
    "job_data['Revenue_Mapped'] = job_data['Revenue'].apply(map_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df5198",
   "metadata": {},
   "source": [
    "## 4. Skill Extraction (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b90c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   python  excel  sql  aws  spark  tableau\n",
      "0       0      0    0    1      0        0\n",
      "1       0      0    1    0      0        0\n",
      "2       1      1    0    1      0        0\n",
      "3       1      1    1    1      0        0\n",
      "4       1      1    1    0      0        0\n"
     ]
    }
   ],
   "source": [
    "skills_list = ['python', 'excel', 'sql', 'aws', 'spark', 'tableau']\n",
    "\n",
    "for skill in skills_list:\n",
    "    job_data[skill] = job_data['Job Description'].apply(lambda x: 1 if skill in x.lower() else 0)\n",
    "\n",
    "print(job_data[skills_list].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737736d",
   "metadata": {},
   "source": [
    "## 5. Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8b4ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Sector  Sector_label\n",
      "0          Insurance            12\n",
      "1  Business Services             4\n",
      "2  Business Services             4\n",
      "3      Manufacturing            13\n",
      "4  Business Services             4\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "cols_to_encode = ['Sector', 'Type of ownership', 'Industry']\n",
    "\n",
    "for col in cols_to_encode:\n",
    "    job_data[col] = job_data[col].replace('-1', 'Unknown').fillna('Unknown')\n",
    "    job_data[f'{col}_label'] = le.fit_transform(job_data[col])\n",
    "\n",
    "print(job_data[['Sector', 'Sector_label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb688519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. DATASET DIMENSIONS & NULLS ###\n",
      "Final Shape: (649, 29)\n",
      "city          0\n",
      "state         0\n",
      "min_salary    0\n",
      "max_salary    0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "### 2. QUANTITATIVE & ENCODED COLUMNS ###\n",
      "   Sector_label  Industry_label  python  sql  aws Revenue_Mapped\n",
      "0            12              30       0    0    1        Unknown\n",
      "1             4              42       0    1    0            50B\n",
      "2             4              11       1    0    1            10M\n",
      "3            13              15       1    1    1            10M\n",
      "4             4               1       1    1    0        Unknown\n",
      "------------------------------\n",
      "### 3. REVENUE DISTRIBUTION (Mapped) ###\n",
      "Revenue_Mapped\n",
      "10M        253\n",
      "Unknown    229\n",
      "50B        167\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "### 4. DATA TYPES SUMMARY ###\n",
      "min_salary      int64\n",
      "max_salary      int64\n",
      "Sector_label    int64\n",
      "python          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. Check final dimensions and missing values\n",
    "print(\"### 1. DATASET DIMENSIONS & NULLS ###\")\n",
    "print(f\"Final Shape: {job_data.shape}\")\n",
    "print(job_data[['city', 'state', 'min_salary', 'max_salary']].isnull().sum())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 2. Display the newly created Quantitative/Encoded columns\n",
    "print(\"### 2. QUANTITATIVE & ENCODED COLUMNS ###\")\n",
    "cols_to_show = ['Sector_label', 'Industry_label', 'python', 'sql', 'aws', 'Revenue_Mapped']\n",
    "print(job_data[cols_to_show].head())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 3. Summarize the Revenue Mapping\n",
    "print(\"### 3. REVENUE DISTRIBUTION (Mapped) ###\")\n",
    "print(job_data['Revenue_Mapped'].value_counts())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 4. Final Data Types (Formatting Check)\n",
    "print(\"### 4. DATA TYPES SUMMARY ###\")\n",
    "print(job_data.dtypes[['min_salary', 'max_salary', 'Sector_label', 'python']])\n",
    "\n",
    "# 5. Save the cleaned data to a new CSV (Optional but recommended for practicals)\n",
    "# job_data.to_csv(\"DS_jobs_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
